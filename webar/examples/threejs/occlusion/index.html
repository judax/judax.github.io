<!--
/*
 * Copyright 2017 Google Inc. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<!DOCTYPE html>
<html lang="en">
  <head>
  <script>
    // Catch any possible error and show an alert. 
    // Useful for "hacky" debugging.
     window.addEventListener('error', function(event) {
      var errorMessage = event.message;
      var url = event.filename;
      var lineNumber = event.lineno;
      var columnNumber = event.colno;
      alert("ERROR: " + errorMessage + " at " + url + " : " + lineNumber + 
        " : " + columnNumber);
    });
  </script>
  <title>WebAR (Tango) Occlusion ThreeJS Example</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, user-scalable=no,
    minimum-scale=1.0, maximum-scale=1.0">
  <style>
    body {
      font-family: Monospace;
      background-color: #000000;
      margin: 0px;
      overflow: hidden;
    }

    #info {
      color: #fff;
      position: absolute;
      bottom: 10px;
      width: 100%;
      text-align: center;
      z-index: 100;
      display:block;

    }

    a { color: skyblue }
  </style>
  </head>
  <body>
    <div id="info">
      <a href="http://threejs.org" target="_blank">three.js</a>
      WebAR (Tango) Occlusion ThreeJS Example
      <a href="https://github.com/judax" target="_blank">Iker Jamardo</a>
    </div>

    <script src="../../libs/third_party/three.js"></script>
    <script src="../../libs/third_party/Detector.js"></script>
    <script src="../../libs/third_party/stats.min.js"></script>
    <script src="../../libs/third_party/VRControls.js"></script>
    <script src="../../libs/third_party/TeapotBufferGeometry.js"></script>
    <script src="../../libs/third_party/dat.gui.min.js"></script>

    <script src="../../libs/THREE.WebAR.js"></script>

    <script>

      // These shaders allow to only render the points that are not in the
      // same plane as the picking plane.
      // The distance uniform is a threshold to determine a marging to consider
      // a point in the picking plane or not.
      // The varying v_discard is used to let the fragment shader know which
      // points should be discarded and which should not.
      var points_vertexShader =
        "attribute vec3 position;\n" +
        "uniform float size;\n" +
        "uniform mat4 modelViewMatrix;\n" +
        "uniform mat4 projectionMatrix;\n" +
        "uniform vec4 plane;\n" +
        "uniform float distance;\n" +
        "varying float v_discard;\n" +
        "void main(void) {\n" +
        "  vec4 v4Position = vec4(position, 1.0);\n" +
        "  float d = dot(plane, v4Position);\n" +
        "  v_discard = 0.0;\n" +
        "  if (abs(d) < distance) v_discard = 1.0;\n" +
        "  gl_PointSize = size;\n" +
        "  gl_Position = projectionMatrix * modelViewMatrix * v4Position;\n" +
        "}";

      var points_fragmentShader =
        "precision mediump float;\n" +
        "uniform vec3 color;\n" +
        "uniform float opacity;\n" +
        "varying float v_discard;\n" +
        "void main(void) {\n" +
        "  if (v_discard > 0.0) discard;\n" +
        "  gl_FragColor = vec4( color, opacity );\n" +
        "}";

      function GUI() {
        this.showSeeThroughCamera = true;
        this.usePointCloudForDepth = true;
        this.transformPoints = true;
        return this;
      }

      if ( ! Detector.webgl ) Detector.addGetWebGLMessage();

      var container, stats;
      var cameraOrtho, cameraPersp, cameraScene, scene, renderer, cameraMesh;
      var pointsScene, pointCloud, points;
      var vrDisplay;
      var model;
      var gui;
      var pos = new THREE.Vector3(); // Avoid GC.

      var MODEL_SIZE_IN_METERS = 0.1;

      // WebAR is currently based on the WebVR API so try to find the right
      // VRDisplay instance.
      if (navigator.getVRDisplays) {
        navigator.getVRDisplays().then(function(vrDisplays) {
          if (vrDisplays && vrDisplays.length > 0) {
            for (var i = 0; !vrDisplay && i < vrDisplays.length; i++) {
              vrDisplay = vrDisplays[i];
              if (vrDisplay.displayName !== "Tango VR Device") {
                vrDisplay = null;
              }
            }
          }
          if (!vrDisplay) {
            alert("No Tango WebAR VRDisplay found. Falling back to a video.");
          }
          init(vrDisplay);
          updateAndRender();  
        });
      }
      else {
        alert("No navigator.getVRDisplays. Falling back to a video.");
        init();
        updateAndRender();
      }

      function init(vrDisplay) {
        // Initialize the dat.GUI.
        var datGUI = new dat.GUI();
        gui = new GUI();
        datGUI.add(gui, "showSeeThroughCamera").name("Show seethrough camera");
        datGUI.add(gui, "usePointCloudForDepth").name("Use point cloud for depth");
        datGUI.add(gui, "transformPoints").name("Transform points");

        // Initialize everything related to ThreeJS.
        container = document.createElement( 'div' );
        document.body.appendChild( container );

        // Create the see through camera scene and camera
        cameraScene = new THREE.Scene();
        cameraOrtho = new THREE.OrthographicCamera( -1, 1, 1, -1, 0, 100 );
        cameraMesh = THREE.WebAR.createVRSeeThroughCameraMesh(vrDisplay);
        cameraScene.add(cameraMesh);

        // Create the 3D scene and camera
        scene = new THREE.Scene();
        // Use the THREE.WebAR utility to create a perspective camera
        // suited to the actual see through camera parameters.
        cameraPersp = 
          THREE.WebAR.createVRSeeThroughCamera(vrDisplay, 0.01, 100);
        // Create a model to be placed in the world using picking
        model = new THREE.Mesh(new THREE.TeapotBufferGeometry(MODEL_SIZE_IN_METERS, 15), 
          new THREE.MeshLambertMaterial( {color: 0x888888 } ));
        // Apply a rotation to the model so it faces in the direction of the
        // normal of the plane when the picking based reorientation is done
        model.geometry.applyMatrix(
          new THREE.Matrix4().makeRotationZ(THREE.Math.degToRad(-90)));
        model.position.set(0, 0, -2);
        scene.add(model);

        // Everything related to the point cloud that uses its own scene
        // to render it specifically for occlusion
        pointsScene = new THREE.Scene();
        // Use a custom shader for the points so the points that are considered
        // to be in the same plane as the picking plane are discarded.
        // This way, the model will not be occluded by the points in the 
        // same plane as the picking plane.
        var pointsMaterial = new THREE.RawShaderMaterial({
          uniforms: {
            size: { value: 30 },
            opacity: { value: 0.1 },
            color: { value: new THREE.Color(0xffffff) },
            plane: { value: new THREE.Vector4() },
            distance: { value: 0.05 }
          },
          vertexShader: points_vertexShader,
          fragmentShader: points_fragmentShader
        });
        pointCloud = new THREE.WebAR.VRPointCloud(vrDisplay, true);
        points = new THREE.Points(pointCloud.getBufferGeometry(),
          pointsMaterial);
        // Points are changing all the time so calculating the frustum culling
        // volume is not very convenient.
        points.frustumCulled = false;
        pointsScene.add(points);

        // Control the perspective camera using the VR pose.
        vrControls = new THREE.VRControls(cameraPersp);

        // Add some lighting
        var directionalLight = new THREE.DirectionalLight( 0xffffff, 0.5 );
        directionalLight.position.set( 0, 1, 0);
        scene.add( directionalLight );

        // Create the renderer
        renderer = new THREE.WebGLRenderer();
        renderer.setPixelRatio( window.devicePixelRatio );
        renderer.setSize( window.innerWidth, window.innerHeight );
        // It is important to specify that the color buffer should not be
        // automatically cleared. The see through camera will render the whole
        // background.
        renderer.autoClear = false;
        document.body.appendChild( renderer.domElement );

        // Create a way to measure performance
        stats = new Stats();
        container.appendChild( stats.dom );

        // Control the resizing of the window to correctly display the scene.
        window.addEventListener( 'resize', onWindowResize, false );

        // Wherever the user clicks in the screen, place the model.
        renderer.domElement.addEventListener("click", function(event) {
          pos.x = event.pageX / window.innerWidth;
          pos.y = event.pageY / window.innerHeight;
          picking();
        });

        // Control the rotation of the model
        var lastX = 0;
        renderer.domElement.addEventListener("touchstart", function(event) {
          if (event.changedTouches.length > 0)
            lastX = event.changedTouches[0].pageX;
        });
        renderer.domElement.addEventListener("touchmove", function(event) {
            if (event.changedTouches.length > 0 && vrDisplay) {
              var x = event.changedTouches[0].pageX;
              var diffX = x - lastX;
              lastX = x;
              model.rotateX(THREE.Math.degToRad(diffX));
            }
        });

      }

      function picking() {
        if (vrDisplay) {
          var pointAndPlane = 
            vrDisplay.getPickingPointAndPlaneInPointCloud(pos.x, pos.y);
          if (pointAndPlane) {
            // Orient and position the model in the picking point according
            // to the picking plane. The offset is half of the model size.
            THREE.WebAR.
              positionAndRotateObject3DWithPickingPointAndPlaneInPointCloud(
                pointAndPlane, model, MODEL_SIZE_IN_METERS / 2);
            // Provide the point material with the plane so it can discard 
            // the points that are considered to be in the plane.
            points.material.uniforms.plane.value.fromArray(
              pointAndPlane.plane);
          }
          else {
            console.warn("Could not retrieve the correct point and plane.");
          }
        }
      }

      function onWindowResize() {
        THREE.WebAR.resizeVRSeeThroughCamera(vrDisplay, cameraPersp);
        renderer.setSize( window.innerWidth, window.innerHeight );
      }

      function updateAndRender() {
        // UPDATE

        stats.update();

        // Update the perspective scene
        vrControls.update();

        // Update the point cloud. Only if the point cloud will be shown the
        // geometry is also updated.
        pointCloud.update(gui.usePointCloudForDepth, 0, gui.transformPoints);

        // If continuous picking is enabled, use the center of the screen
        // to continuously pick.
        if (gui.continuousPicking) {
          pos.x = 0.5;
          pos.y = 0.5;
          picking();
        }

        // Make sure that the camera is correctly displayed depending on the
        // device and camera orientations.
        THREE.WebAR.updateCameraMeshOrientation(vrDisplay, cameraMesh);

        // RENDER

        // Render the see through camera scene
        renderer.clear();

        if (gui.showSeeThroughCamera)
          renderer.render( cameraScene, cameraOrtho );

        // Render the perspective scene
        renderer.clearDepth();

        // Render the point cloud
        if (this.gui.usePointCloudForDepth) {
          this.renderer.context.colorMask( false, false, false, false );
          this.renderer.render(pointsScene, cameraPersp);
          this.renderer.context.colorMask( true, true, true, true );
        }

        renderer.render( scene, cameraPersp );

        requestAnimationFrame( updateAndRender );
      }

    </script>
  </body>
</html>
